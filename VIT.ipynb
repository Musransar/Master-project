{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"zBNrLq4SJnFg","executionInfo":{"status":"ok","timestamp":1685942178642,"user_tz":-300,"elapsed":4506,"user":{"displayName":"Mustasar Hussain","userId":"17370095289860096598"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from keras.layers import Dense,AveragePooling2D\n","from keras.models import Model\n","from keras import layers\n","import tensorflow as tf\n","from keras.utils import to_categorical\n","from sklearn.utils import shuffle\n","from keras.metrics import CategoricalAccuracy,BinaryAccuracy,Recall,Precision\n","from sklearn.metrics import confusion_matrix,classification_report\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.image import ImageDataGenerator\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WHTi22r0L7Sp"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive',force_remount=True)"]},{"cell_type":"code","source":["import os\n","tb_dir='/content/drive/MyDrive/tbx11k-simplified/Dataset/TB'\n","len(os.listdir(tb_dir))"],"metadata":{"id":"WOxfwl-Z79Qq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"988LKWYOjtMD"},"outputs":[],"source":["import os\n","dataset_url = '/content/drive/MyDrive/tbx11k-simplified'\n","os.chdir('/content/drive/MyDrive/tbx11k-simplified')\n"]},{"cell_type":"code","source":["dataset=os.path.join(dataset_url,\"Dataset\")"],"metadata":{"id":"giFZgjTwEw6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_labels={\"TB\":0,\n","               \"HEALTHY\":1,\n","               \"SICK\":2}"],"metadata":{"id":"dQ0sxZsXF0Wl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_labels['TB']"],"metadata":{"id":"Sc5YxKsWGB-d"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fewz_OWJnFz"},"outputs":[],"source":["\n","images,labels=[],[]\n","for folder in os.listdir(dataset):\n","  count=0\n","  print(folder)\n","  for i,img in enumerate(os.listdir(os.path.join(dataset,folder))):\n","    img=cv2.imread(os.path.join(dataset,os.path.join(folder,img)))\n","    img=cv2.resize(img,(256,256))\n","    count=count+1\n","    if i%100==0:\n","      print(i)\n","    images.append(img)\n","    labels.append(folder_labels[folder])\n","    if count==1000:\n","      break\n"]},{"cell_type":"code","source":["import pandas as pd\n","pd.Series(labels).value_counts()"],"metadata":{"id":"l9hR67mWGR1P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"88mg20QgEvIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-SY-J6UbrsS"},"outputs":[],"source":["len(images),len(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLUx77GFbter"},"outputs":[],"source":["lab=pd.Series(labels).unique()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpfw54Cgbxjy"},"outputs":[],"source":["image=np.array(images)\n","print(image.shape)\n"]},{"cell_type":"code","source":["label=np.array(labels)"],"metadata":{"id":"V6NfdylfIHd_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4YG1ozuIJnF-"},"outputs":[],"source":["## split train / test\n","\n","indices_train, indices_test = train_test_split(list(range(image.shape[0])), train_size=0.8, test_size=0.2, shuffle=True)\n","\n","x_train = image[indices_train]\n","y_train = label[indices_train]\n","x_test = image[indices_test]\n","y_test = label[indices_test]\n","\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HT8tcsifJnGE"},"outputs":[],"source":["y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xoN5US_CJnGH"},"outputs":[],"source":["from keras.utils import to_categorical"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1Rc61mxJnGK"},"outputs":[],"source":["y_train = keras.utils.to_categorical(y_train)\n","y_test = keras.utils.to_categorical(y_test)\n","\n","y_train.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YnrGEdiqJnGN"},"outputs":[],"source":["y_train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YMEBCm3JnGT"},"outputs":[],"source":["y_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAVopVgVJnGY"},"outputs":[],"source":["x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e6PR_fFtJnGe"},"outputs":[],"source":["pip install -U tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xmcqmKddJnGi"},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import tensorflow_addons as tfa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3CXiizsJnGk"},"outputs":[],"source":["num_classes = 3\n","input_shape = (256,256, 3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_y8EcHARJnGn"},"outputs":[],"source":["x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W2mzwLA-JnGp"},"outputs":[],"source":["batch_size = 16\n","num_epochs = 50\n","image_size = 256  # We'll resize input images to this size\n","patch_size = 8  # Size of the patches to be extract from the input images\n","num_patches = (image_size // patch_size) ** 2\n","projection_dim = 64\n","num_heads = 4\n","transformer_units = [\n","    projection_dim * 2,\n","    projection_dim,\n","]  # Size of the transformer layers\n","transformer_layers = 8\n","mlp_head_units = [2048, 1024] "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T7N1Rg31JnGr"},"outputs":[],"source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.Normalization(),\n","        layers.Resizing(image_size, image_size),\n","        layers.RandomFlip(\"horizontal\"),\n","        layers.RandomRotation(factor=0.02),\n","        layers.RandomZoom(\n","            height_factor=0.2, width_factor=0.2\n","        ),\n","    ],\n","    name=\"data_augmentation\",\n",")\n","# Compute the mean and the variance of the training data for normalization.\n","data_augmentation.layers[0].adapt(x_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRPnitRQJnGu"},"outputs":[],"source":["def mlp(x, hidden_units, dropout_rate):\n","    for units in hidden_units:\n","        x = layers.Dense(units, activation=tf.nn.gelu)(x) # GELU activation function\n","        x = layers.Dropout(dropout_rate)(x) # Dropout layer\n","    return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AEEIXDmfJnGx"},"outputs":[],"source":["class Patches(layers.Layer):\n","    def __init__(self, patch_size):\n","        super(Patches, self).__init__()\n","        self.patch_size = patch_size\n","\n","    def call(self, images):\n","        batch_size = tf.shape(images)[0]\n","        patches = tf.image.extract_patches(\n","            images=images,\n","            sizes=[1, self.patch_size, self.patch_size, 1],\n","            strides=[1, self.patch_size, self.patch_size, 1],\n","            rates=[1, 1, 1, 1],\n","            padding=\"VALID\",\n","        )\n","        patch_dims = patches.shape[-1]\n","        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n","        return patches"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQmv56szJnGz"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(4, 4))\n","image = x_train[np.random.choice(range(x_train.shape[0]))]\n","plt.imshow(image.astype(\"uint8\"))\n","plt.axis(\"off\")\n","\n","resized_image = tf.image.resize(\n","    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",")\n","patches = Patches(patch_size)(resized_image)\n","print(f\"Image size: {image_size} X {image_size}\")\n","print(f\"Patch size: {patch_size} X {patch_size}\")\n","print(f\"Patches per image: {patches.shape[1]}\")\n","print(f\"Elements per patch: {patches.shape[-1]}\")\n","\n","n = int(np.sqrt(patches.shape[1]))\n","plt.figure(figsize=(4, 4))\n","for i, patch in enumerate(patches[0]):\n","    ax = plt.subplot(n, n, i + 1)\n","    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n","    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n","    plt.axis(\"off\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wK8-YB06L2La"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsHSJcJoJnG1"},"outputs":[],"source":["class PatchEncoder(layers.Layer):\n","    def __init__(self, num_patches, projection_dim):\n","        super(PatchEncoder, self).__init__()\n","        self.num_patches = num_patches\n","        self.projection = layers.Dense(units=projection_dim)\n","        self.position_embedding = layers.Embedding(\n","            input_dim=num_patches, output_dim=projection_dim\n","        )\n","\n","    def call(self, patch):\n","        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n","        encoded = self.projection(patch) + self.position_embedding(positions)\n","        return encoded"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MsmgA_fKJnG3"},"outputs":[],"source":["def create_vit_classifier():\n","    inputs = layers.Input(shape=input_shape)\n","    # Augment data.\n","    augmented = data_augmentation(inputs)\n","    # Create patches.\n","    patches = Patches(patch_size)(augmented)\n","    # Encode patches.\n","    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n","\n","    # Create multiple layers of the Transformer block.\n","    for _ in range(transformer_layers):\n","        # Layer normalization 1.\n","        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","        # Create a multi-head attention layer.\n","        attention_output = layers.MultiHeadAttention(\n","            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n","        )(x1, x1)\n","        # Skip connection 1.\n","        x2 = layers.Add()([attention_output, encoded_patches])\n","        # Layer normalization 2.\n","        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n","        # MLP.\n","        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n","        # Skip connection 2.\n","        encoded_patches = layers.Add()([x3, x2])\n","\n","    # Create a [batch_size, projection_dim] tensor.\n","    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n","    representation = layers.Flatten()(representation)\n","    representation = layers.Dropout(0.5)(representation)\n","    # Add MLP.\n","    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n","    # Classify outputs.\n","    logits = layers.Dense(num_classes, activation=\"sigmoid\")(features)\n","    # Create the Keras model.\n","    model = keras.Model(inputs=inputs, outputs=logits)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wy3HbqHUJnG4"},"outputs":[],"source":["from matplotlib import pyplot\n","from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score,cohen_kappa_score,roc_auc_score,confusion_matrix,classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X-Cu-i3OA00a"},"outputs":[],"source":["# compile the model\n","model = create_vit_classifier()\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n","    loss=keras.losses.CategoricalCrossentropy(),\n","    metrics=[keras.metrics.CategoricalAccuracy(name=\"accuracy\")],\n",")\n","model.summary()\n","# train the model\n","history = model.fit(\n","    x_train, y_train, batch_size=16, epochs=50, validation_data=(x_test, y_test)\n",")\n","\n","# evaluate the model\n","loss, accuracy = model.evaluate(x_test, y_test)\n","print(f\"Test loss: {round(loss, 2)}\")\n","print(f\"Test accuracy: {round(accuracy * 100, 2)} %\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6zWP3ZoCeCxu"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","output_folder = 'Results'\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","# summarize history for accuracy\n","plt.plot(history.history['accuracy'],label=\"train_acc\")\n","plt.plot(history.history['val_accuracy'],label=\"val_acc\")\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.savefig(\"/content/drive/MyDrive/tbx11k-simplified/Results/accuracyplot.png\")\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'],label=\"train_loss\")\n","plt.plot(history.history['val_loss'],label=\"val_loss\")\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['Train', 'Validation'], loc='upper left')\n","plt.savefig(\"/content/drive/MyDrive/tbx11k-simplified/Results/lossplot.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cUBmEUggfBQw"},"outputs":[],"source":["y_pred=model.predict(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8_loCdcPfxmS"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"562YlM4HfoKJ"},"outputs":[],"source":["y_pred=np.argmax(y_pred,axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Z5qLFv6fumD"},"outputs":[],"source":["y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cgYld1gvf-3g"},"outputs":[],"source":["len(y_test),len(y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3x3kB7xBgXWi"},"outputs":[],"source":["y_test=np.argmax(y_test, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6V6fdAMgGWz"},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","cm = confusion_matrix(y_test, y_pred)\n","cm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kXZqPvi-hdzU"},"outputs":[],"source":["import seaborn as sns\n","plt.figure(figsize = (10,7))\n","sns.heatmap(cm, annot=True, fmt='g')\n","plt.savefig(\"/content/drive/MyDrive/tbx11k-simplified/Results/CM.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NVH3gVgWh4fQ"},"outputs":[],"source":["classes = ['TB','HEALTHY','SICK']  \n","from sklearn.metrics import classification_report\n","print(classification_report(y_test, y_pred,target_names=classes))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jhfo-C6XG30l"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DPSpIcimJnG7"},"outputs":[],"source":["# history\n","print(f'The model has a best accuracy of {round(max(history.history[\"accuracy\"])*100,2)}% and a best loss of {round(min(history.history[\"loss\"]),2)}')\n"," \n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}